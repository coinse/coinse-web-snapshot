---
layout: page
title: CS489 Computer Ethics and Social Issues (Autumn 2020)
---

<div class="tab">
  <button class="tablinks" onclick="openTab(event, 'Syllabus')" id="defaultOpen">Syllabus</button>
  <button class="tablinks" onclick="openTab(event, 'Schedule')">Schedule</button>
  <button class="tablinks" onclick="openTab(event, 'Assignments')">Assignments</button>
  <button class="tablinks" onclick="openTab(event, 'Projects')">Projects</button>
  <button class="tablinks" onclick="openTab(event, 'Reading List')">Reading List</button>
</div>

<!-- Tab content -->
<div id="Syllabus" class="tabcontent" markdown="1">

<!-- ## Course Registration Update (08/26)

Among those who emailed me earlier, everyone who actually applied online was approved. Assuming that those did not apply has found other courses, I subsequently approved those who emailed AND applied **after** 24th August. The class size is now 62, which is more than double the original limit. I don't think I will approve any more students, unless someone drops out.


## Regarding Cource Registration (08/24)

During the registration period, the number of people who wanted to take this class exceeded all expectations. The class size was initially limited to 30 to balance the grading load (all assignments are essays and I wanted to give individualy written feedback, however brief). But it seems like the overall demand for courses (and not just for CS489) is simply too high - I am aware that students are frustrated of the availability of courses. As such, I am accepting additional students, based on the list of people who contacted me before 24th August. If you've already contacted me, then you may have an email from me - apply, and I will approve. 

I've decided to double the size, but beyond 60 seems not really feasible. I will see how many people actually take up this opportunity. If there are any seats left, then I will approve the rest based on the order of application.

Some modifications to the course/feedback structure will be inevitable. **Please remember that you cannot do well in this course simply by sitting down and listening to other people - you have your share of work to do!** -->


### Lectures
Time: 10:30-12:00, Mondays and Wednesdays
Location: Online (see the Campuswire course page for the zoom link)

### Lecturer

Shin Yoo [shin.yoo@kaist.ac.kr](mailto:shin.yoo@kaist.ac.kr)
Office: E3-1 Room 2405

### Communication

All class announcements, as well as Q&A, will take place using Campuswire. **You are required to join if you want to continue this course.** It is strongly recommended that you install the mobile client, to get notifications. **The invitation link will be shared during the first class.**

### Syllabus

This course is concerned with a broad range of ethical issues that are closely related to, or have their origins at, computing technology and their uses. The aim of the course is not to find *the* answer to these problems. Rather, we will examine them from various angles together and discuss what we can do.

Another very important apsect of this course is that we will go through concrete technology that can help us while dealing with these issues. For example, instead of just saying that privacy is important, we will also look at techniques that allow you to effetively hide your data. Instead of just saying that a society should be fair, we will look at techniques that test large software systems for fairness. 

### Prerequisite

- **Active Class Participation**: a non-trivial part of this course is in-class presentation and discussion. If you just sit quietly, you will not gain much from this course. Also, note that class participation is 30% of the whole grade.
- **Strong programming skills**: you are required to develop an **individual** course project. There will be also a number of hands-on sessions where we will program together during the class.
- Unix/Linux-savvy: you should be familiar with the usual build tools and Unix/Linux command line environments.
- Git-aware: you will be required to submit a github repository as part of your project deliverables.
- Ideally, a laptop you can bring to the classroom. **If this becomes a problem, let me know**.

### Evaluation

- 30% Course Participation
- 40% Courseworks
- 30% Course Project

### Teaching Assistant

- [Gabin An](https://coinse.kaist.ac.kr/members/gabin/), agb94@kaist.ac.kr

</div>

<div id="Schedule" class="tabcontent" markdown="1">
### Lecture Schedule

These dates and topics are tentative.

- 08/31: [Introduction & Admin](/assets/files/teaching/cs489/cs489-slide00.pdf)
- 09/02: [Perspectives on Ethics](/assets/files/teaching/cs489/cs489-slide01.pdf)
- 09/07: [Professional Computer Ethics](/assets/files/teaching/cs489/cs489-slide02.pdf)
- 09/09: [Technology and Public Discourse](/assets/files/teaching/cs489/cs489-slide03.pdf)
  + [YouTube, the Great Radicalizer](https://coinse.kaist.ac.kr/assets/files/teaching/cs489/Tufekci.pdf)
- 09/14: [Right to be forgotten](/assets/files/teaching/cs489/cs489-slide05.pdf) / [Automation](/assets/files/teaching/cs489/cs489-slide06.pdf)
- 09/16: [Ethical Issues in Research](/assets/files/teaching/cs489/cs489-slide04.pdf)
- 09/21: [Fairness, Accountability, and Transparency](/assets/files/teaching/cs489/cs489-fat-juhokim.pdf) (Guest Lecture: [Dr. Juho Kim, KIXLab, School of Computing, KAIST](http://juhokim.com))
- 09/23: Project Discussions #1
  + Team 11, 7, 4, 3, 5, 2, 14
- 09/28: Project Discussions #2
  + Team 1, 13, 19, 12, 9, 8, 6
- 09/30: **No Lecture: Chuseok Holiday**
- 10/05: Paper Seminar
  + Team 9: [Gender differences and bias in open source: pull request acceptance of women versus men](https://peerj.com/articles/cs-111/)
  + Team 10: [Explaining Explanations in AI](https://dl.acm.org/doi/10.1145/3287560.3287574)
- 10/07: ** No Lecture **
- 10/12: [AI and Ethics](/assets/files/teaching/cs489/cs489-slide07.pdf)
- 10/14: Paper Seminar
  + Team 4: [Auditing radicalization pathways on YouTube](https://dl.acm.org/doi/10.1145/3351095.3372879)
  + Tean 7: [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://dl.acm.org/doi/10.1145/3287560.3287600)
- 10/19: **No Lecture: Midterm Week**
- 10/22: **No Lecture: Midterm Week**
- 10/26: Paper Seminar
  + Team 2: [A method to detect license inconsistencies in large-scale open source projects](https://ieeexplore.ieee.org/document/7180091)
  + Team 5: [The Moral Machine Experiment](https://www.nature.com/articles/s41586-018-0637-6)
- 10/28: Paper Seminar
  + Team 14: [Artificial Intelligence as a Socratic Assistant for Moral Enhancement](https://link.springer.com/article/10.1007%2Fs12152-019-09401-y)
  + Team 3: [Reducing energy consumption using genetic improvement](https://dl.acm.org/citation.cfm?id=2754752)
- 11/02: Project Milestone Day #1
  + Team 14, 13, 12, 6, 5, 10, 7
- 11/04: Project Milestone Day #2
  + Team 3, 4, 9, 1, 8, 2, 11
- 11/09: Class Debate #1: Technology and Pandemic
  + [An open letter to developers of Mask Alimi (in Korean)](https://www.facebook.com/permalink.php?story_fbid=1039608496422939&id=100011213958452) ([here](/assets/files/teaching/cs489/openletter.pdf)'s the mostly machine translated English version)
  + [COVID-19 and Contact Tracing Apps: Ethical Challenges for a Social Experiment on a Global Scale](https://link.springer.com/article/10.1007/s11673-020-10016-9#Sec2), Lucivero et al., Journal of Bioethical Inquiry, 2020.
- 11/11: Paper Seminar
  + Team 6: [Race and the beauty premium: Mechanical Turk workers’ evaluations of Twitter accounts](https://www.tandfonline.com/doi/full/10.1080/1369118X.2018.1543443)
  + Team 11: [Exposing DeepFake videos by detecting face warping artifacts, Exposing Deep Fakes using inconsistent head poses](https://arxiv.org/abs/1811.00656, https://arxiv.org/abs/1811.00661)
- 11/16: Class Debate #2 on Outsourcing Human Labour - MTurkers and Inmates
    + [Google Cloud Human Labelling Price Table](https://cloud.google.com/ai-platform/data-labeling/pricing)
    + [How much money can you make on Amazon Mechanical Turk?](https://thehustle.co/making-money-on-amazon-mechanical-turk/)
    + [The Internet is enabling a new kind of poorly paid hell](/assets/files/teaching/cs489/mturk_atlantic.pdf)
    + [Inmates in Finland are training AI as part of prison labour](/assets/files/teaching/cs489/inmates_verge.pdf)
- 11/18: Homomorphic Encryption (Guest Lecture by [Prof. Donghun Hyun, Dept. of Mathematics, SNU](https://y-kast.or.kr/kr/member/member_view.php?idx=52))
- 11/23: [k-Anonymity and Secure Multiparty Computation](/assets/files/teaching/cs489/cs489-slide08.pdf)
  + [Protecting respondents identities in microdata release](https://ieeexplore.ieee.org/document/971193)
  + [Learning Without Peeking: Secure Multi-party Computation Genetic Programming](https://link.springer.com/chapter/10.1007/978-3-319-99241-9_13)
- 11/25: [Intellectual Property, Copyright, and Provenance](/assets/files/teaching/cs489/cs489-slide09.pdf)
- 11/30: Paper Seminar
  + Team 1: [Avoiding the intrinsic unfairness of the trolley problem](https://dl.acm.org/citation.cfm?id=3194770.3194772)
  + Team 13: [Analyzing Biases in Perception of Truth in News Stories and Their Implications for Fact Checking](https://dl.acm.org/citation.cfm?id=3287581)
- 12/02: [Environmental Impacts](/assets/files/teaching/cs489/cs489-slide10.pdf)
    + [What do programmers know about software energy consumption?](https://www.computer.org/csdl/magazine/so/2016/03/mso2016030083/13rRUNvgz83)
    + [Data-Oriented Characterization of Application-Level Energy Optimization](https://link.springer.com/chapter/10.1007/978-3-662-46675-9_21)
- 12/07: Paper Seminar
  + Team 12: [Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification](http://proceedings.mlr.press/v81/buolamwini18a.html), [IBM Response](http://gendershades.org/docs/ibm.pdf)
  + Team 8: [Computational Fact Checking from Knowledge Networks](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0128193)
- 12/09: Class Debate #3
  + [Embedded EthiCS: Integrating Ethics Across CS Education](https://cacm.acm.org/magazines/2019/8/238345-embedded-ethics/fulltext)
- 12/14: *No Lecture: Midterm Week*
- 12/16: *No Lecture: Midterm Week*
</div>


<div id="Assignments" class="tabcontent" markdown="1">
## Assignments

### **Assignment 1: Ethics, Computers, and Our lives**

Pick a media coverage (e.g., a newspaper or magazine article) of an event that you think is related to both computer science and ethics. Write a minimum 1,000 words essay to describe what the ethical issue is, how it is related to computer science, and what your opinion is. Include a link to the article you chose: it can be in either Korean or English (if you really have to choose something in other language, please contact me and explain why). 

**Due on 7th September before the class begins**. Submit a PDF via KLMS (Assignment 1).

### **Assignment 2: Questions about AI Democratisation**

Read the following article: [AI Democratization in the Era of GPT-3r](https://medium.com/@mark_riedl/ai-democratization-in-the-era-of-gpt-3-8b91891f91cb). Near the end, the article raises five questions. Write a minimum 500 words essay which discusses and tries to answer at least one of these questions. 

**Due on 28th September before the class begins**. Submit a PDF via KLMS (Assignment 2).

<!-- ### **Assignment 3: Hippocratic Oath for Computer Scientists**

Some people think that computer scientists should take what corresponds to [Hippocratic oath](https://en.wikipedia.org/wiki/Hippocratic_Oath) that physicians take: you can read about the argument [here](https://www.theguardian.com/science/2019/aug/16/mathematicians-need-doctor-style-hippocratic-oath-says-academic-hannah-fry). Your assignment is to draft your own version of such an oath. Also briefly discuss your thoughts about how taking such an oath can affect CS majors.

**Due on 19th October before the class begins**. Submit a PDF via KLMS (Assignment 3). -->

### **Assignment 3: Autonomous Driving**

There seem to be two major, polarised opinions about autonomous driving. Some claim that autonomous driving technology is not fully ready yet but corporates are being pushy because of the expected profit (e.g., no human driver cost). Others claim that autonomous driving vehicles will be much safer than human drivers even with the current or near-future technology, so we should adopt them as fast as we can. Read the following article, and describe what your thoughts are between these two argument: [Collision course: why are cars killing more and more pedestrians?](https://www.theguardian.com/technology/2019/oct/03/collision-course-pedestrian-deaths-rising-driverless-cars). Write it up as a minimum 500 word essay. Your essay should explicitly state your view.

**Due on 19th October before the class begins**. Submit a PDF via KLMS (Assignment 3).

### **Assignment 4: Thoughts on Gig Economy**

Write a 500~1,000 words essay detailing your thoughts about [gig economy](https://en.wikipedia.org/wiki/Gig_worker). Technology has contributed a lot to enable this new form of work. Some people actively argue that it is the inevitable future of jobs (e.g. [The online jobs revolution: Freelance is future of work](https://www.the-star.co.ke/sasa/lifestyle/2020-05-08-the-online-jobs-revolution-freelance-is-future-of-work/)). Others think it is closer to exploitation and needs to be resisted (e.g. [Strike 2.0: how gig economy workers are using tech to fight back](https://www.theguardian.com/books/2019/aug/31/the-new-resistance-how-gig-economy-workers-are-fighting-back?CMP=Share_iOSApp_Other)). Where do you stand? How can technology help make it fairer and more just?

**Due on 9th November before the class begins**. Submit a PDF via KLMS (Assignment 4).

</div>

<div id="Projects" class="tabcontent" markdown="1">

### Project Aim

The aim of the term project is to put the practical knowledge obtained during the course to an actual use. Any project topic is acceptable, as long as it directly touches on the theme of ethics. 

- You can develop an app (e.g., Ethical Decision Making [AppStore](https://apps.apple.com/us/app/ethical-decision-making/id799710217), [Google Play](https://play.google.com/store/apps/details?id=com.mcae.decision&hl=en)).
- You can write tools/frameworks that promote/implement certain ethical issues (e.g., secure deep learning using homomorphic encryption) and evaluate it empirically.
- You can design a human experiment about a topic related to ethics (e.g., something akin to The Moral Machine).

Choices are endless, but it has to involve some technical depths. There will be an opportunity to present the initial ideas and get feedback (Project sales pitch sessions).

Each team is supposed to prepare and upload three videos.

- Project pitch: 5 minute video explaining what your project is. **Upload by 16th September**.
- Project milestone: 5 minute video reporting the progress and the stutus of the project. **Upload by 26th October**.
- Project final presentation: 5~10 minute video that contains the final presentation. **Upload by 9th December**.

**The submission of course project is by the end of 18th December 2020.** Every **individual** should submit the following through KLMS:

- **Group report**: this should be a detailed report of your project, in whatever format that you think is the best. 
- **A GitHub repo link**: As announced at the beginning of the course, you should also submit a **GitHub repository** that contains everything about your project. The link should be included in the group report.
- **Individual report**: this report should contain two parts - first, describe what your own contribution to the project was, and second, evaluate your team members using on a scale of 0 to 10, with a brief justification for your evaluation.

</div>

<div id="Reading List" class="tabcontent" markdown="1">

### Recommended Reading List

This list is not an obligation, but contains highly recommended readings if you want to widen your views around the issues we will handle throughout the course. 

- [The People vs. Tech: How Internet is killing democracy (and how we save it)](https://www.penguin.co.uk/books/111/1116305/the-people-vs-tech/9781785039065.html), Jamie Bartlett
- [Spotify Teardown: Inside the Black Box of Streaming Music](https://mitpress.mit.edu/books/spotify-teardown), Maria Eriksson, Rasmus Fleischer, Anna Johansson, Pelle Snickars, and Patrick Vonderau
- [The Most Human Human](https://brianchristian.org/the-most-human-human/), Brian Christian / [가장 인간적인 인간](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=17470932), 브라이언 크리스천
- [Would you kill the fat man? The trolley problem and what your answer tells us about right and wrong](https://press.princeton.edu/titles/10074.html), David Edmonds / [저 뚱뚱한 남자를 죽이시겠습니까? 당신이 피할 수 없는 도덕적 딜레마에 대한 질문](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=52115511), 데이비드 에드먼즈

</div>

<script>

if (window.location.href == sessionStorage.getItem('lastVisitedUrl')) {
    // When this page is lastly visited: Reopen the lastly visted tab
    try {
        i = sessionStorage.getItem('currentButtonIndex')
        document.getElementsByClassName("tablinks")[i].click()
    } catch (e) { 
        document.getElementById("defaultOpen").click();
    }
} else {
    // Get the element with id="defaultOpen" and click on it
    document.getElementById("defaultOpen").click();
}
    
</script>

[slide00]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide00.pdf
[slide01]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide01.pdf
[slide02]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide02.pdf
[slide03]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide03.pdf
[slide04]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide04.pdf
[slide05]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide05.pdf
[slide06]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide06.pdf
[slide07]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide07.pdf
[slide08]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide08.pdf
[slide09]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide09.pdf
[slide10]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide10.pdf
[slide11]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cs453slide11.pdf
[cw1]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cw1.pdf
[cw2]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cw2.pdf
[cw3]: {{site.baseurl}}/assets/files/teaching/2019/cs453/cw3.pdf